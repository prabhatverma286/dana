# hold all the default parameters
# All evaluations use these parameters

cartpole = {'network': 'mlp',
            'seed': None,
            'lr': 1e-4,
            'batch_size': 32,
            'prioritized_replay': False,
            'prioritized_replay_alpha': 0.6,
            'prioritized_replay_beta0': 0.4,
            'prioritized_replay_eps': 1e-6,
            'param_noise': False,
            'dueling': False,
            'learning_starts': 1000,
            'total_timesteps': 100000,
            'buffer_size': 50000,
            'exploration_fraction': 0.1,
            'exploration_final_eps': 0.03,
            'train_freq': 3,
            'target_network_update_freq': 800,
            'gamma': 0.97
}

pong = {
        'network': "conv_only",
        'seed': None,
        'batch_size': 32,
        'prioritized_replay': False,
        'prioritized_replay_alpha': 0.6,
        'prioritized_replay_beta0': 0.4,
        'prioritized_replay_eps': 1e-6,
        'param_noise': False,
        'convs': [(32, 8, 4), (64, 4, 2), (64, 3, 1)],
        'hiddens': [256],
        'dueling': True,
        'lr': 1e-4,
        'total_timesteps': int(1e7),
        'buffer_size': 10000,
        'exploration_fraction': 0.1,
        'exploration_final_eps': 0.01,
        'train_freq': 4,
        'learning_starts': 10000,
        'target_network_update_freq': 1000,
        'gamma': 0.99
}

breakout = {
        'network': "conv_only",
        'seed': None,
        'batch_size': 32,
        'prioritized_replay_beta0': 0.4,
        'prioritized_replay_eps': 1e-6,
        'param_noise': False,
        'convs': [(32, 8, 4), (64, 4, 2), (64, 3, 1)],
        'hiddens': [256],
        'dueling': True,
        'lr': 1e-4,
        'total_timesteps': int(1e7),
        'buffer_size': int(1e6),
        'exploration_fraction': 0.1,
        'exploration_final_eps': 0.01,
        'train_freq': 4,
        'learning_starts': 80000,
        'target_network_update_freq': 40000,
        'prioritized_replay': True,
        'prioritized_replay_alpha': 0.6,
        'gamma': 0.99,
}

sonic_the_hedgehog = {
        'network': "conv_only",
        'seed': None,
        'batch_size': 32,
        'prioritized_replay_beta0': 0.4,
        'prioritized_replay_eps': 1e-6,
        'param_noise': False,
        'convs': [(32, 8, 4), (64, 4, 2), (64, 3, 1)],
        'hiddens': [256],
        'dueling': True,
        'lr': 1e-4,
        'total_timesteps': 300000,
        'buffer_size': int(1e6),
        'exploration_fraction': 0.1,
        'exploration_final_eps': 0.01,
        'train_freq': 4,
        'learning_starts': 80000,
        'target_network_update_freq': 40000,
        'prioritized_replay': True,
        'prioritized_replay_alpha': 0.6,
        'gamma': 0.99,
}

sonic_the_hedgehog_dqfd = {
    'demo_file': 'SonicTheHedgehog-Genesis-GreenHillZone.Act1-0000',
    'expert_model_name': 'expert_model_final.h5',
    'lr': 1e-4,
    'buffer_size': 500000,
    'total_timesteps_expert': 130000,
    'total_timesteps_normal': 170000,
    'exploration_min_eps': 0.01,
    'exploration_eps_start': 0.99,
    'demo_ratio': 0.8,
    'batch_size': 32,
    'learning_starts': 20000,
    'gamma': 0.99,
    'target_network_update_freq': 10000,
    'prioritized_replay_alpha': 0.4,
    'prioritized_replay_beta': 0.6,
    'prioritized_replay_eps': 0.001,
    'dqn_loss': 1.0,
    'nstep_loss': 1.0,
    'slmc_loss': 1.0,
    'l2_loss': 10e-5,
    'dueling': True,
    'reward_clipping': False,
    'allow_backtracking': True,
    'train_expert': True
}